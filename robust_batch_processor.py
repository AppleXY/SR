#!/usr/bin/env python3
"""
æ”¯æŒæ–­ç‚¹ç»­ä¼ çš„NIPS 2024è®ºæ–‡æ‰¹é‡è§£æå·¥å…·
ç‰¹æ€§:
- è‡ªåŠ¨æ£€æµ‹å·²å¤„ç†è®ºæ–‡ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
- é”™è¯¯åå¯é‡å¯ç»§ç»­å¤„ç†
- ç¾è§‚çš„è¿›åº¦æ¡æ˜¾ç¤º
- è¯¦ç»†çš„æ—¥å¿—è®°å½•
- ç»“æœéªŒè¯å’Œç»Ÿè®¡
"""
import os
import sys
import json
import time
import requests
import zipfile
import io
from datetime import datetime
from tqdm import tqdm
import logging
from pathlib import Path
import signal
import threading
from collections import defaultdict

class RobustPaperProcessor:
    def __init__(self, api_token, output_file="nips2024_papers.jsonl", 
                 log_file="processing.log", checkpoint_file="checkpoint.json"):
        self.api_token = api_token
        self.output_file = output_file
        self.log_file = log_file
        self.checkpoint_file = checkpoint_file
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_token}"
        }
        
        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total': 0,
            'completed': 0,
            'successful': 0,
            'failed': 0,
            'skipped': 0,
            'start_time': None,
            'errors': defaultdict(int)
        }
        
        # ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        self.should_stop = False
        
    def _signal_handler(self, signum, frame):
        """å¤„ç†ä¸­æ–­ä¿¡å·ï¼Œä¼˜é›…é€€å‡º"""
        self.logger.info(f"\næ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨ä¼˜é›…é€€å‡º...")
        self.should_stop = True
        self._save_checkpoint()
        
    def _load_checkpoint(self):
        """åŠ è½½æ£€æŸ¥ç‚¹ï¼Œè·å–å·²å¤„ç†è®ºæ–‡åˆ—è¡¨"""
        if os.path.exists(self.checkpoint_file):
            try:
                with open(self.checkpoint_file, 'r', encoding='utf-8') as f:
                    checkpoint = json.load(f)
                self.stats.update(checkpoint.get('stats', {}))
                self.logger.info(f"åŠ è½½æ£€æŸ¥ç‚¹ï¼šå·²å¤„ç† {checkpoint.get('completed_count', 0)} ç¯‡è®ºæ–‡")
                return set(checkpoint.get('completed_papers', []))
            except Exception as e:
                self.logger.warning(f"åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
                return set()
        return set()
    
    def _save_checkpoint(self):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        try:
            completed_papers = self._get_completed_papers_from_file()
            checkpoint = {
                'stats': self.stats,
                'completed_papers': list(completed_papers),
                'completed_count': len(completed_papers),
                'timestamp': datetime.now().isoformat()
            }
            
            with open(self.checkpoint_file, 'w', encoding='utf-8') as f:
                json.dump(checkpoint, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
    
    def _get_completed_papers_from_file(self):
        """ä»è¾“å‡ºæ–‡ä»¶ä¸­è·å–å·²å®Œæˆçš„è®ºæ–‡ID"""
        completed = set()
        if os.path.exists(self.output_file):
            try:
                with open(self.output_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            data = json.loads(line)
                            completed.add(data.get('paper_id'))
            except Exception as e:
                self.logger.warning(f"è¯»å–å·²å®Œæˆè®ºæ–‡åˆ—è¡¨å¤±è´¥: {e}")
        return completed
    
    def _save_result(self, result):
        """çº¿ç¨‹å®‰å…¨åœ°ä¿å­˜ç»“æœ"""
        try:
            with open(self.output_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(result, ensure_ascii=False) + '\n')
                f.flush()  # ç«‹å³å†™å…¥ç£ç›˜
        except Exception as e:
            self.logger.error(f"ä¿å­˜ç»“æœå¤±è´¥ {result.get('paper_id', 'unknown')}: {e}")
    
    def submit_task(self, paper_id):
        """æäº¤å•ä¸ªè®ºæ–‡çš„è§£æä»»åŠ¡"""
        pdf_url = f"https://openreview.net/pdf?id={paper_id}"
        
        task_data = {
            "url": pdf_url,
            "is_ocr": True,
            "enable_formula": True,
            "enable_table": True,
            "language": "en",
            "data_id": paper_id
        }
        
        try:
            response = requests.post(
                "https://mineru.net/api/v4/extract/task",
                headers=self.headers,
                json=task_data,
                timeout=30
            )
            
            if response.status_code != 200:
                return None, f"HTTP {response.status_code}: {response.text[:200]}"
            
            result = response.json()
            if result.get("code") != 0:
                return None, result.get("msg", "Unknown API error")
            
            return result["data"]["task_id"], None
            
        except requests.exceptions.Timeout:
            return None, "æäº¤ä»»åŠ¡è¶…æ—¶"
        except Exception as e:
            return None, str(e)
    
    def wait_for_completion(self, task_id, paper_id, max_wait_time=1800):
        """ç­‰å¾…ä»»åŠ¡å®Œæˆï¼Œæ”¯æŒä¸­æ–­æ£€æŸ¥"""
        start_time = time.time()
        status_url = f"https://mineru.net/api/v4/extract/task/{task_id}"
        check_interval = 15  # 15ç§’æ£€æŸ¥ä¸€æ¬¡
        
        while time.time() - start_time < max_wait_time:
            if self.should_stop:
                return None, "ç”¨æˆ·ä¸­æ–­"
            
            try:
                response = requests.get(status_url, headers=self.headers, timeout=30)
                
                if response.status_code != 200:
                    return None, f"çŠ¶æ€æŸ¥è¯¢å¤±è´¥: {response.status_code}"
                
                result = response.json()
                if result.get("code") != 0:
                    return None, f"çŠ¶æ€APIé”™è¯¯: {result.get('msg')}"
                
                state = result["data"]["state"]
                
                if state == "done":
                    full_zip_url = result["data"]["full_zip_url"]
                    return self.download_and_extract(full_zip_url, paper_id)
                    
                elif state == "failed":
                    err_msg = result["data"].get("err_msg", "Unknown error")
                    return None, f"ä»»åŠ¡å¤±è´¥: {err_msg}"
                    
                # ç­‰å¾…çŠ¶æ€
                time.sleep(check_interval)
                
            except requests.exceptions.Timeout:
                self.logger.warning(f"çŠ¶æ€æŸ¥è¯¢è¶…æ—¶ {paper_id}")
                time.sleep(check_interval)
            except Exception as e:
                self.logger.warning(f"çŠ¶æ€æŸ¥è¯¢å¼‚å¸¸ {paper_id}: {e}")
                time.sleep(check_interval)
        
        return None, "ä»»åŠ¡è¶…æ—¶"
    
    def download_and_extract(self, zip_url, paper_id):
        """ä¸‹è½½ZIPæ–‡ä»¶å¹¶æå–markdownå†…å®¹"""
        try:
            response = requests.get(zip_url, timeout=120)
            
            if response.status_code != 200:
                return None, f"ä¸‹è½½ZIPå¤±è´¥: {response.status_code}"
            
            with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:
                # æŸ¥æ‰¾markdownæ–‡ä»¶
                markdown_files = [name for name in zip_file.namelist() if name.endswith('.md')]
                
                if not markdown_files:
                    return None, "ZIPä¸­æœªæ‰¾åˆ°Markdownæ–‡ä»¶"
                
                # è¯»å–ç¬¬ä¸€ä¸ªmarkdownæ–‡ä»¶
                markdown_content = zip_file.read(markdown_files[0]).decode('utf-8')
                
                return {
                    "paper_id": paper_id,
                    "pdf_url": f"https://openreview.net/pdf?id={paper_id}",
                    "markdown_content": markdown_content,
                    "status": "success",
                    "markdown_file": markdown_files[0],
                    "content_length": len(markdown_content),
                    "processed_at": datetime.now().isoformat()
                }, None
                
        except Exception as e:
            return None, f"ZIPå¤„ç†é”™è¯¯: {str(e)}"
    
    def process_single_paper(self, paper_id, pbar=None):
        """å¤„ç†å•ä¸ªè®ºæ–‡çš„å®Œæ•´æµç¨‹"""
        try:
            # æ›´æ–°è¿›åº¦æ¡æè¿°
            if pbar:
                pbar.set_description(f"å¤„ç† {paper_id}")
            
            # æäº¤ä»»åŠ¡
            task_id, error = self.submit_task(paper_id)
            if error:
                self.stats['errors'][f"æäº¤å¤±è´¥: {error}"] += 1
                result = {
                    "paper_id": paper_id,
                    "status": "error",
                    "error": f"æäº¤å¤±è´¥: {error}",
                    "processed_at": datetime.now().isoformat()
                }
                self._save_result(result)
                self.stats['failed'] += 1
                return False
            
            self.logger.info(f"å·²æäº¤ä»»åŠ¡ {paper_id}: {task_id}")
            
            # ç­‰å¾…å®Œæˆ
            if pbar:
                pbar.set_description(f"ç­‰å¾… {paper_id}")
            
            result, error = self.wait_for_completion(task_id, paper_id)
            if error:
                self.stats['errors'][f"å¤„ç†å¤±è´¥: {error}"] += 1
                result = {
                    "paper_id": paper_id,
                    "status": "error",
                    "error": error,
                    "task_id": task_id,
                    "processed_at": datetime.now().isoformat()
                }
                self._save_result(result)
                self.stats['failed'] += 1
                return False
            
            # ä¿å­˜æˆåŠŸç»“æœ
            self._save_result(result)
            self.stats['successful'] += 1
            self.logger.info(f"æˆåŠŸå¤„ç† {paper_id}: {result['content_length']} å­—ç¬¦")
            return True
            
        except Exception as e:
            self.logger.error(f"å¤„ç†å¼‚å¸¸ {paper_id}: {e}")
            self.stats['errors'][f"å¼‚å¸¸: {str(e)}"] += 1
            result = {
                "paper_id": paper_id,
                "status": "error",
                "error": f"å¤„ç†å¼‚å¸¸: {str(e)}",
                "processed_at": datetime.now().isoformat()
            }
            self._save_result(result)
            self.stats['failed'] += 1
            return False
        finally:
            self.stats['completed'] += 1
            if pbar:
                pbar.update(1)
                pbar.set_postfix(
                    æˆåŠŸ=self.stats['successful'],
                    å¤±è´¥=self.stats['failed'],
                    è·³è¿‡=self.stats['skipped']
                )
    
    def process_papers(self, paper_ids):
        """æ‰¹é‡å¤„ç†è®ºæ–‡ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ """
        # åŠ è½½æ£€æŸ¥ç‚¹
        completed_papers = self._load_checkpoint()
        
        # è¿‡æ»¤å·²å®Œæˆçš„è®ºæ–‡
        pending_papers = [pid for pid in paper_ids if pid not in completed_papers]
        
        self.stats['total'] = len(paper_ids)
        self.stats['skipped'] = len(completed_papers)
        self.stats['start_time'] = datetime.now().isoformat()
        
        if not pending_papers:
            self.logger.info("æ‰€æœ‰è®ºæ–‡å·²å¤„ç†å®Œæˆï¼")
            return
        
        self.logger.info(f"æ€»è®¡: {len(paper_ids)} ç¯‡è®ºæ–‡")
        self.logger.info(f"å·²å®Œæˆ: {len(completed_papers)} ç¯‡")
        self.logger.info(f"å¾…å¤„ç†: {len(pending_papers)} ç¯‡")
        self.logger.info(f"ç»“æœä¿å­˜åˆ°: {self.output_file}")
        
        # åˆ›å»ºè¿›åº¦æ¡
        with tqdm(
            total=len(pending_papers),
            desc="æ‰¹é‡å¤„ç†",
            unit="ç¯‡",
            bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}] {postfix}"
        ) as pbar:
            
            for paper_id in pending_papers:
                if self.should_stop:
                    self.logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œä¿å­˜è¿›åº¦...")
                    break
                
                success = self.process_single_paper(paper_id, pbar)
                
                # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
                if self.stats['completed'] % 10 == 0:
                    self._save_checkpoint()
                
                # å‡ºç°é”™è¯¯æ—¶çŸ­æš‚ä¼‘æ¯
                if not success:
                    time.sleep(2)
        
        # æœ€ç»ˆä¿å­˜æ£€æŸ¥ç‚¹
        self._save_checkpoint()
        self._print_final_stats()
    
    def _print_final_stats(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*60)
        print("ğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡")
        print("="*60)
        print(f"æ€»è®¡è®ºæ–‡: {self.stats['total']}")
        print(f"æˆåŠŸå¤„ç†: {self.stats['successful']}")
        print(f"å¤„ç†å¤±è´¥: {self.stats['failed']}")
        print(f"è·³è¿‡å·²å®Œæˆ: {self.stats['skipped']}")
        print(f"å®é™…å¤„ç†: {self.stats['completed']}")
        
        if self.stats['start_time']:
            start_time = datetime.fromisoformat(self.stats['start_time'])
            duration = datetime.now() - start_time
            print(f"å¤„ç†è€—æ—¶: {duration}")
            
            if self.stats['successful'] > 0:
                avg_time = duration.total_seconds() / self.stats['successful']
                print(f"å¹³å‡è€—æ—¶: {avg_time:.1f}ç§’/ç¯‡")
        
        print(f"\nğŸ“ ç»“æœæ–‡ä»¶: {self.output_file}")
        print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {self.log_file}")
        print(f"ğŸ“ æ£€æŸ¥ç‚¹æ–‡ä»¶: {self.checkpoint_file}")
        
        # æ˜¾ç¤ºé”™è¯¯ç»Ÿè®¡
        if self.stats['errors']:
            print(f"\nâŒ é”™è¯¯ç»Ÿè®¡:")
            for error_type, count in self.stats['errors'].items():
                print(f"  {error_type}: {count}")
        
        print("="*60)

def load_env():
    """ä».envæ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡"""
    env_path = '.env'
    if os.path.exists(env_path):
        with open(env_path, 'r') as f:
            for line in f:
                line = line.strip()
                if '=' in line and not line.startswith('#'):
                    key, value = line.split('=', 1)
                    os.environ[key.strip()] = value.strip().strip('"').strip("'")
    return os.environ.get('API_TOKEN') or os.environ.get('API')

def main():
    # åŠ è½½API token
    api_token = load_env()
    if not api_token:
        print("âŒ æœªæ‰¾åˆ°API tokenï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶")
        return
    
    # è¯»å–è®ºæ–‡IDåˆ—è¡¨
    paper_ids_file = 'nips2024_reject_id.txt'
    if not os.path.exists(paper_ids_file):
        print(f"âŒ æœªæ‰¾åˆ°è®ºæ–‡IDæ–‡ä»¶: {paper_ids_file}")
        return
    
    with open(paper_ids_file, 'r') as f:
        paper_ids = [line.strip() for line in f if line.strip()]
    
    print(f"ğŸš€ NIPS 2024 è®ºæ–‡æ‰¹é‡è§£æå·¥å…· v2.0")
    print(f"ğŸ“„ æ‰¾åˆ° {len(paper_ids)} ä¸ªè®ºæ–‡ID")
    
    # åˆ›å»ºå¤„ç†å™¨å¹¶å¼€å§‹å¤„ç†
    processor = RobustPaperProcessor(api_token)
    processor.process_papers(paper_ids)

if __name__ == "__main__":
    main()